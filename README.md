# AI Security Research & Red Teaming
A collection of vulnerability research, prompt injection proofs-of-concept, and LLM security audits.

## Skills
- Semantic Prompt Injection
- Guardrail Bypassing
- LLM Logic Flaw Identification
- API Security Testing
